# AI Blogger - Environment Configuration
# Copy this file to .env and fill in your API keys

# ============================================
# FREE LLM PROVIDERS (pick one or more)
# ============================================

# Groq - RECOMMENDED (fastest, generous free tier)
# Get free API key: https://console.groq.com/keys
GROQ_API_KEY=

# Together AI - Good alternative (free credits on signup)
# Get free API key: https://api.together.xyz/settings/api-keys
TOGETHER_API_KEY=

# Hugging Face - Fallback option (rate limited)
# Get free API key: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=

# ============================================
# PROVIDER SELECTION
# ============================================
# Options: 'auto', 'groq', 'together', 'huggingface', 'ollama'
# 'auto' tries providers in order: groq > together > huggingface > ollama
LLM_PROVIDER=auto

# ============================================
# LOCAL OLLAMA (if not using online providers)
# ============================================
# If running Ollama locally, no config needed
# Ollama URL defaults to http://host.docker.internal:11434
